{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import os\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenAI to generate questions and answers for fine-tuning purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "\n",
    "reader = PdfReader(\"generative_agent.pdf\")\n",
    "\n",
    "number_of_pages = len(reader.pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Q&As pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking the document into overlapped chunks\n",
    "### 1. Remove irrelevant content (such as authors, doi, ect)\n",
    "### 2. Make page content overlapped with previous and succeeding pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pages_sentences = []\n",
    "pages_content = []\n",
    "pages_clean_text = []\n",
    "NUM_OVERLAP_SENTENCES = 10\n",
    "\n",
    "for page_num, page in enumerate(reader.pages):\n",
    "  page_text = page.extract_text()\n",
    "  page_text = page_text.replace('arXiv, April, 2023, J. S.  Park, J. C.  O’Brien, C. J.  Cai, M.  Morris, P.  Liang, M. S', '')\n",
    "  page_text = page_text.replace('arXiv, April, 2023, J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein', '')\n",
    "  page_text = page_text.replace('[cs.HC]  7 Apr 2023', '')\n",
    "  page_text = page_text.replace('arXiv:2304.03442v1', '')\n",
    "  \n",
    "  sentences = re.split(r'[.]', page_text)\n",
    "  pages_clean_text.append(page_text)\n",
    "  pages_sentences.append(sentences)\n",
    "\n",
    "for page_num, page in enumerate(pages_clean_text):\n",
    "  prev_page_overlapped_sentences = \"\" if page_num == 0 else '. '.join(pages_sentences[page_num - 1][-NUM_OVERLAP_SENTENCES:])\n",
    "  next_page_overlapped_sentences = \"\" if page_num == len(pages_clean_text) - 1 else '. '.join(pages_sentences[page_num + 1][:NUM_OVERLAP_SENTENCES])\n",
    "  pages_content.append(prev_page_overlapped_sentences + '\\n' + page + '\\n' + next_page_overlapped_sentences)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'generative_agent.txt'), 'w') as f:\n",
    "    for page in pages_content:\n",
    "        f.write(page + '\\n ---- \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Q&As pairs for each document pages, \n",
    "### 1. The page contents are overlapped by 10 sentences with the previous page to add context to the data\n",
    "### 2. For each page, the model is asked to summarize the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"The page content consists of a conversation between individuals discussing their plans, reactions to unexpected events, and reflections on their current inspirations and interactions. It also contains hypothetical scenarios related to Ayesha Khan's interests and potential gifts for her.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='')\n",
    "\n",
    "qas = []\n",
    "messages = []\n",
    "summaries = []\n",
    "\n",
    "for page_num, page in enumerate(reader.pages):\n",
    "  sentences = re.split(r'[.?!]', page.extract_text())\n",
    "\n",
    "for page_num, page in enumerate(pages_content):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": \"You act as a training data generator for a GPT 3.5 fine-tuning job. Your job is to generate questions and answer those questions for the content of a research paper.\" \n",
    "        \" The whole paper is broken into multiple sections. Therefore, all of the following content is from the same research paper and presented to you in order.\"\n",
    "        \" You only generate questions, those are and highly-relevant to the research paper, and the correct answers to the corresponding questions. \"\n",
    "        \" The questions and answers in following format: \"\\\n",
    "        \"Question 1: \\n Answer 1: \\n\\nQuestion 2: \\n Answer 2: Question 3: \\n Answer 3: \" \n",
    "        \"\\n\\nQuestion 4: \\n Answer 4: \\n\\nQuestion 4: \\n Answer 2: Question 5: \\n Answer 5: \"\n",
    "        \"\\n\\nQuestion 6: \\n Answer 6: \\n\\nQuestion 7: \\n Answer 7: Question 8: \\n Answer 8: \"\n",
    "        \"\\n\\nQuestion 9: \\n Answer 9: Question 10: \\n Answer 10: \"},\n",
    "        {\"role\": \"user\", \"content\": f\"{page}\"}\n",
    "      ]\n",
    "    )\n",
    "  qas.append({'page': page_num, 'completion': completion.choices[0].message.content})\n",
    "  \n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You act as a training data generator for a GPT 3.5 fine-tuning job. Summarise the page content as precisely as possible. \" \\\n",
    "        \"{\\\"summary\\\": \\\"\\\"}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{page}\"}\n",
    "      ]\n",
    "      \n",
    "    )\n",
    "  summaries.append(completion.choices[0].message.content)\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Concat the pages summaries, generate Q&As on all summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the main focus of the paper introduced in the summaries?\n",
      "\n",
      "Answer 1: The main focus of the paper is on generative agents that simulate believable human behavior in an interactive sandbox environment inspired by The Sims.\n",
      "\n",
      "Question 2: How are generative agents instantiated in the interactive sandbox environment discussed in the paper?\n",
      "\n",
      "Answer 2: Generative agents are instantiated in an interactive sandbox environment where users can interact with a small town of 25 agents using natural language.\n",
      "\n",
      "Question 3: What are some of the behaviors that the generative agents are capable of simulating?\n",
      "\n",
      "Answer 3: The generative agents are capable of waking up, cooking, working, creating art, forming opinions, noticing others, and engaging in conversations.\n",
      "\n",
      "Question 4: How are the generative agents evaluated in the paper?\n",
      "\n",
      "Answer 4: The generative agents are evaluated based on their believable individual and emergent social behaviors, demonstrating the effectiveness of their architecture and evaluations.\n",
      "\n",
      "Question 5: What is the approach used in creating generative agents for simulating human behavior?\n",
      "\n",
      "Answer 5: The approach involves extending a large language model to store the agent's experiences in natural language, synthesize memories, and retrieve them dynamically to plan behavior.\n",
      "\n",
      "Question 6: What does the article propose as the challenge in creating generative agents?\n",
      "\n",
      "Answer 6: The article discusses the challenge of creating generative agents that can simulate human behavior and the approach of maintaining a memory stream to address this challenge.\n",
      "\n",
      "Question 7: How is the sandbox environment in Smallville described?\n",
      "\n",
      "Answer 7: The sandbox environment, Smallville, is described as a world where generative agents interact with each other and users, including the affordances of a small village.\n",
      "\n",
      "Question 8: What is the role of reflections in the architecture of generative agents?\n",
      "\n",
      "Answer 8: Reflections in the architecture of generative agents are described as higher-level, abstract thoughts generated periodically to guide their behavior over time.\n",
      "\n",
      "Question 9: How are generative agents evaluated in Smallville?\n",
      "\n",
      "Answer 9: Generative agents in Smallville are evaluated through controlled evaluations, including interviews and comparisons with human-authored responses, to assess their believability.\n",
      "\n",
      "Question 10: What is the contribution of the study related to generative agents' architecture and evaluations?\n",
      "\n",
      "Answer 10: The study's significant contribution lies in the introduction of an architecture that effectively extends a large language model to store and retrieve the agents' experiences, enabling them to dynamically plan and reflect on their behavior, as well as demonstrating the effectiveness of the architecture through evaluations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "page_num = 1\n",
    "str_summaries = \"\"\n",
    "for page_summary in summaries:\n",
    "    str_summaries += f\"\\nPage {page_num}'s summary: {page_summary}\"\n",
    "    page_num += 1\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You act as a training data generator for a GPT 3.5 fine-tuning job. Your job is to generate questions and answer those questions for the content of a research paper. The whole paper is broken into multiple sections. Each page's summary will be provided.\"\n",
    "        \" Provide questions and answers those are involved content from different pages. \"\n",
    "        \" The questions and answers in following format: \"\\\n",
    "        \"\\n\\nQuestion 1: \\n Answer 1: \\n\\nQuestion 2: \\n Answer 2: Question 3: \\n Answer 3: \" \n",
    "        \"\\n\\nQuestion 4: \\n Answer 4: \\n\\nQuestion 5: \\n Answer 5: \"\n",
    "        \"\\n\\nQuestion 6: \\n Answer 6: \\n\\nQuestion 7: \\n Answer 7: \\n\\nQuestion 8: \\n Answer 8: \"\n",
    "        \"\\n\\nQuestion 9: \\n Answer 9: Question 10: \\n Answer 10: \"\n",
    "        \"\\n\\nQuestion 11: \\n Answer 11: \\n\\nQuestion 12: \\n Answer 12: Question 13: \\n Answer 13: \" \n",
    "        \"\\n\\nQuestion 14: \\n Answer 14: \\n\\nQuestion 15: \\n Answer 15: \"\n",
    "        \"\\n\\nQuestion 16: \\n Answer 16: \\n\\nQuestion 17: \\n Answer 17: \\n\\nQuestion 18: \\n Answer 18: \"\n",
    "        \"\\n\\nQuestion 19: \\n Answer 19: Question 20: \\n Answer 20: \"},\n",
    "        {\"role\": \"user\", \"content\": \"Summary: \" + str_summaries}\n",
    "      ]\n",
    ")\n",
    "\n",
    "qas.append({'page': -1, 'completion': completion.choices[0].message.content})\n",
    "\n",
    "with open(os.path.join('data', 'page_summary.txt'), 'w') as f:\n",
    "    f.writelines(str_summaries)\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_examples = \"\"\n",
    "\n",
    "for qa in qas:\n",
    "    page_num = qa['page']\n",
    "    data_str = qa['completion'].replace('\\n\\nAnswer', '\\nAnswer').replace(': \\n', ': ')\n",
    "    data_list = data_str.split('\\n\\n')\n",
    "    for pair in data_list:\n",
    "        if pair[:8] != 'Question':\n",
    "            continue\n",
    "        q, a = pair.split('Answer')\n",
    "        q, a = q.split(': ')[-1].replace('?\\n', '?'), a.split(': ')[-1]\n",
    "        qa_examples += json.dumps({\"messages\": [{\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\\n\\n\"\n",
    "                                                        \"Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on topics related to provided documents.\"\n",
    "                                                        \"As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\n\"\n",
    "                                                        \"Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on the topics.\"}, \n",
    "                                                       {\"role\": \"user\", \"content\": f\"{q}\"}, \n",
    "                                                       {\"role\": \"assistant\", \"content\": f\"{a}\"}]}) + '\\n'\n",
    "\n",
    "\n",
    "with open(os.path.join('data', 'QA_pairs.jsonl'), 'w') as f:\n",
    "    f.writelines(qa_examples[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "with open(os.path.join('data', 'QA_pairs.jsonl'), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "train, test = train_test_split(np.array(lines), test_size=0.2)\n",
    "train, val = train_test_split(np.array(train), test_size=0.2)\n",
    "\n",
    "with open(os.path.join('data', 'QA_pairs_train.jsonl'), 'w') as f:\n",
    "    f.writelines(train)\n",
    "\n",
    "with open(os.path.join('data', 'QA_pairs_val.jsonl'), 'w') as f:\n",
    "    f.writelines(val)\n",
    "\n",
    "with open(os.path.join('data', 'QA_pairs_test.jsonl'), 'w') as f:\n",
    "    f.writelines(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"messages\": [{\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\\\\n\\\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on topics related to provided documents.As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\\\n\\\\nAdditionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on the topics.\"}, {\"role\": \"user\", \"content\": \"What is the contribution of the study related to generative agents\\' architecture and evaluations?\"}, {\"role\": \"assistant\", \"content\": \"The study\\'s significant contribution lies in the introduction of an architecture that effectively extends a large language model to store and retrieve the agents\\' experiences, enabling them to dynamically plan and reflect on their behavior, as well as demonstrating the effectiveness of the architecture through evaluations.\"}]}'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

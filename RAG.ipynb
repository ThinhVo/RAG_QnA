{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "\n",
    "with open(os.path.join('data', 'generative_agent.txt'), 'r') as f:\n",
    "    texts = f.read()\n",
    "\n",
    "pages = texts.split('\\n ---- \\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into chunks, \n",
    "* Chunks are separated by `\\n --- \\n` in the file `generative_agent.txt`.\n",
    "* See data pre-processing in `data_preparation.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 78557.81it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for idx, page in enumerate(tqdm(pages)):\n",
    "    if not page:\n",
    "        continue\n",
    "    chunks.append({\n",
    "        'id': str(uuid4()),\n",
    "        'page_content': page,\n",
    "        'chunk': idx,\n",
    "        'page_num': idx+1\n",
    "    } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "embeddings = embeddings_model.embed_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "\n",
    "chroma_collection_name = \"test\"\n",
    "\n",
    "\n",
    "try:\n",
    "    collection = chroma_client.create_collection(name=chroma_collection_name)\n",
    "except:\n",
    "    collection = chroma_client.get_collection(name=chroma_collection_name)\n",
    "\n",
    "collection.add(\n",
    "    documents=pages,\n",
    "    metadatas=[{\"source\": \"generative_agent.txt\"}] * len(pages),\n",
    "    ids=[f'page {i}' for i in range(len(pages))],\n",
    "    embeddings=embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 23)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count(), len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "chroma_collection_name = \"test\"\n",
    "vectorstore = Chroma(collection_name=chroma_collection_name, client=chroma_client, embedding_function=embeddings_model)\n",
    "# results = vectorstore.similarity_search(query=\"We required that our evaluators be in the U.S., fluent in English,\" \\\n",
    "#                                                 \"and older than 18 years old. They were paid at the rate of $15.00\" \\\n",
    "#                                                 \"per hour [ 86], and provided consent by agreeing to a consent form\" \\\n",
    "#                                                 \"that was approved by our institution’s IRB. We recruited 100 evalu-\" \\\n",
    "#                                                 \"ators from Prolific, an online platform for recruiting study partic-\" \\\n",
    "#                                                 \"ipants [ 82], whose participation lasted around 30 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A generative agent is an agent that can engage in interactions with other agents and react to changes in the environment. It produces behavior by synthesizing and retrieving relevant information to condition language model output. They make important inferences and maintain long-term coherence.  Without these mechanisms, large language models can output behavior, but the resulting agents may not react based on the agent’s past experiences, may not make important inferences, and may not maintain long-term coherence.  Challenges with long-term planning and coherence remain [ 18]\\neven with today’s most performant models such as GPT-4.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "# Prompt template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "            Use three sentences maximum and keep the answer as detailed as possible.\n",
    "\n",
    "            {context}\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# RAG Chain\n",
    "fine_tuned_model='ft:gpt-3.5-turbo-1106::8dJxkf8w'\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "llm = ChatOpenAI(model_name=fine_tuned_model, temperature=0.9)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain.invoke(\"What is a generative agent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A generative agent is an agent that draws on generative models to simulate believable human behavior and produces believable simulacra of both individual and emergent group behavior, such as in the example of starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party and creating emergent social behaviors, such as spreading invitations to the party over the next two days, making new acquaintances, asking each other out on dates to the party, and coordinating to show up for the party together at the right time.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"What is a generative agent?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper introduces generative agents, interactive computational agents that simulate human behavior. The authors demonstrated the potential of generative agents by manifesting them as non-player characters in a Sims-style game world and simulating their lives in it. It evaluation of the generative agents’ behavior was limited to a relatively short timescale, and future research should aim to observe their behavior over an extended period to gain a more comprehensive understanding of their capabilities and limitations. The authors of the paper are Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"Please summarize the generative agent paper. What is it flaws? Who is the authors?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
